Traceback (most recent call last):
  File "predict.py", line 164, in <module>
    main()
  File "predict.py", line 35, in main
    model1.load_state_dict(torch.load(config.first_model,
  File "/public/home/cxiao/.local/lib/python3.8/site-packages/torch/serialization.py", line 607, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/public/home/cxiao/.local/lib/python3.8/site-packages/torch/serialization.py", line 882, in _load
    result = unpickler.load()
  File "/public/home/cxiao/.local/lib/python3.8/site-packages/torch/serialization.py", line 857, in persistent_load
    load_tensor(data_type, size, key, _maybe_decode_ascii(location))
  File "/public/home/cxiao/.local/lib/python3.8/site-packages/torch/serialization.py", line 846, in load_tensor
    loaded_storages[key] = restore_location(storage, location)
  File "/public/home/cxiao/.local/lib/python3.8/site-packages/torch/serialization.py", line 827, in restore_location
    return default_restore_location(storage, str(map_location))
  File "/public/home/cxiao/.local/lib/python3.8/site-packages/torch/serialization.py", line 175, in default_restore_location
    result = fn(storage, location)
  File "/public/home/cxiao/.local/lib/python3.8/site-packages/torch/serialization.py", line 157, in _cuda_deserialize
    return obj.cuda(device)
  File "/public/home/cxiao/.local/lib/python3.8/site-packages/torch/_utils.py", line 79, in _cuda
    return new_type(self.size()).copy_(self, non_blocking)
  File "/public/home/cxiao/.local/lib/python3.8/site-packages/torch/cuda/__init__.py", line 528, in _lazy_new
    return super(_CudaBase, cls).__new__(cls, *args, **kwargs)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
/public/home/cxiao/Study/git_pro/kits20_xcd/utils/validation.py:389: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(case_pred, dtype=torch.int8), images, new_spacing, z_thick
INFO: masks len:9
INFO: masks len:5
INFO: masks len:3
INFO: masks len:8
INFO: masks len:7
INFO: masks len:5
INFO: masks len:6
INFO: masks len:10
INFO: masks len:8
INFO: masks len:6
INFO: masks len:7
INFO: masks len:10
INFO: masks len:4
INFO: masks len:4
INFO: masks len:4
INFO: masks len:7
INFO: masks len:6
INFO: masks len:7
INFO: masks len:3
INFO: masks len:7
INFO: masks len:7
INFO: masks len:11
INFO: masks len:5
INFO: masks len:5
INFO: masks len:5
INFO: masks len:5
INFO: masks len:8
INFO: masks len:8
INFO: masks len:6
INFO: masks len:5
INFO: dice and sds:[[0.81083586 0.55086309]
 [0.21029572 0.06370257]
 [0.21568755 0.0640364 ]]
